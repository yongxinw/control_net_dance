{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Everybody Dance Now\n",
        "Let's make a dancing figure using control net\n"
      ],
      "metadata": {
        "id": "R3XYx4DylI3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install denpendencies"
      ],
      "metadata": {
        "id": "xF5huC0vl3sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q controlnet_aux transformers accelerate\n",
        "!pip install -q git+https://github.com/huggingface/diffusers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17uXnwvklEuz",
        "outputId": "4f761c06-c3f2-4b9a-866c-9308f8c5930a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/202.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/202.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Control Net"
      ],
      "metadata": {
        "id": "43jTMh7Nl6r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First get the pose estimator from control net"
      ],
      "metadata": {
        "id": "AaBwcdxZl-FR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBHiu-CVlCNx"
      },
      "outputs": [],
      "source": [
        "from controlnet_aux import OpenposeDetector\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "openpose = OpenposeDetector.from_pretrained(\"lllyasviel/ControlNet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of what it does:"
      ],
      "metadata": {
        "id": "gtB9kv4hmDQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openpose_image = load_image(\n",
        "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/person.png\"\n",
        ")\n",
        "openpose_image.show()"
      ],
      "metadata": {
        "id": "x9lpO_KzmCrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openpose_image = openpose(openpose_image)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "openpose_image.show()"
      ],
      "metadata": {
        "id": "zAc3psSYvUCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next, get the control net image generator\n",
        "You probably need an A-100 GPU for this. In case of errors while using other types of GPUs, go to stackoverflow.com, ask google, or checkout diffuser's github repository."
      ],
      "metadata": {
        "id": "zZswShUlmU8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, AutoencoderKL, UniPCMultistepScheduler\n",
        "import torch\n",
        "\n",
        "# Initialize ControlNet pipeline.\n",
        "controlnet = ControlNetModel.from_pretrained(\"thibaud/controlnet-openpose-sdxl-1.0\", torch_dtype=torch.float16)\n",
        "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\", controlnet=controlnet, torch_dtype=torch.float16\n",
        ")\n",
        "pipe.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "K5p4TvN5mY6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get your data"
      ],
      "metadata": {
        "id": "pEw8-jmKmp08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to your google drive. You should have uploaded a video to your drive at this point. If you haven't, upload a video now."
      ],
      "metadata": {
        "id": "m9Kvwfg7mxAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilSHs-tdmrhR",
        "outputId": "392bebff-c592-4ea0-8f05-7f0e2e2e6cec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the video into image frames using ffmpeg"
      ],
      "metadata": {
        "id": "eZ4dKRymm8-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p frames\n",
        "!rm frames/*\n",
        "# Usage: !ffmpeg -i <path_to_your_uploaded_video> -vf \"fps=25\" frames/frame%06d.png\n",
        "!ffmpeg -i /content/drive/MyDrive/cai.mp4 -vf \"fps=25\" frames/frame%06d.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bRq1UbJm8mt",
        "outputId": "a2fffd7d-eba1-4054-b545-d7dc6a88635f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'frames/*': No such file or directory\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/cai.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    comment         : vid:v12025gd0000cgn9abjc77ueot8f00mg\n",
            "    encoder         : Lavf58.45.100\n",
            "  Duration: 00:00:59.42, start: 0.000000, bitrate: 687 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1024x576 [SAR 1:1 DAR 16:9], 652 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (HE-AACv2) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 32 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to 'frames/frame%06d.png':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    comment         : vid:v12025gd0000cgn9abjc77ueot8f00mg\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: png, rgb24(pc, gbr/unknown/unknown, progressive), 1024x576 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 png\n",
            "frame= 1479 fps= 32 q=-0.0 Lsize=N/A time=00:00:59.16 bitrate=N/A speed=1.26x    \n",
            "video:385620kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/frames | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhccvOQJufJG",
        "outputId": "bdadea95-97be-494a-f063-9b6d13a27258"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start generating!"
      ],
      "metadata": {
        "id": "pHAVNmOFnPZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/results/"
      ],
      "metadata": {
        "id": "TqblcxIInmtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_frame = 600\n",
        "end_frame = 900\n",
        "prompt = \"Spider man dancing in a desert, high quality, cartoon style\"  # what you want to generate\n",
        "negative_prompt = \"low quality, bad quality\"  # what you don't want to generate\n",
        "\n",
        "for idx, i in enumerate(range(start_frame, end_frame)):\n",
        "    # openpose_image = load_image(f\"/content/vid1/frame{i:06d}.png\")\n",
        "    openpose_image = load_image(f\"/content/frames/frame{i:06d}.png\")\n",
        "    openpose_image = openpose(openpose_image)\n",
        "\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=25,\n",
        "        num_images_per_prompt=1,\n",
        "        image=openpose_image,\n",
        "        generator=torch.manual_seed(97),\n",
        "    ).images\n",
        "    images[0].save(f\"/content/drive/MyDrive/results/frame{idx+1:06d}.png\")\n",
        "    # if i == 10:\n",
        "    #     break"
      ],
      "metadata": {
        "id": "yiav5f2onQ3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assemble the final video from the generated frames"
      ],
      "metadata": {
        "id": "VL49SPV0nst2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage: !ffmpeg -framerate 25 -i <path_to_generate_frames> -c:v libx264 -movflags +faststart -pix_fmt yuv420p <path_to_result_video>\n",
        "!ffmpeg -framerate 25 -i /content/drive/MyDrive/results/frame%06d.png -c:v libx264 -movflags +faststart -pix_fmt yuv420p /content/drive/MyDrive/results/results.mp4"
      ],
      "metadata": {
        "id": "9r6Cqo-VnqZy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}